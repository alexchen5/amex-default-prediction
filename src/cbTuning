import pandas as pd
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV
import catboost as cb
from amex_metric import amex_metric

# reading files for train 
x_train = pd.read_parquet(f'../processed/train.parquet')
y_train = pd.read_csv(f'../input/train_labels.csv').target.values

def lgb_amex_metric(y_true, y_pred):
    """The competition metric with lightgbm's calling convention"""
    return ('amex',
            amex_metric(y_true, y_pred),
            True)

features = [f for f in x_train.columns if f != 'customer_ID' and f != 'target']

# using the amex metric as the scorer for the grid search
scoring = make_scorer(amex_metric, greater_is_better=True)

# individual tests for different hyperparameters
param_test1 = {
 'depth':range(1,10,1)
}
param_test2 = {
 'iterations':[100, 250, 500, 1000],
 'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3]
}
param_test3 = {
 'l2_leaf_reg':[1, 3, 5, 10, 100]
}
param_test4 = {
 'border_count':[5,10,20,50,100,200],
}

# grid search to optimise hyperparameter provided in param_grid
gsearch1 = GridSearchCV(estimator = cb.CatBoostClassifier(iterations= 1000,
    learning_rate= 0.2,
    depth= 5,
    l2_leaf_reg= 3,
    bootstrap_type= 'Bernoulli',
    subsample= 0.7,
    scale_pos_weight= 5,
    border_count=20,
    random_seed=1),
 param_grid = param_test2, scoring=scoring,n_jobs=4, cv=5)
 
gsearch1.fit(x_train[features], y_train)
print(gsearch1.best_params_) 
print(gsearch1.best_score_)